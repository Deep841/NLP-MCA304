{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef18aa6b",
   "metadata": {},
   "source": [
    "## NLP pipeline - Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca62ae3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer, TfidfVectorizer\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8fbecb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.1-cp313-cp313-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/deeplatiyan/miniconda3/lib/python3.13/site-packages (from scikit-learn) (2.2.6)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.1-cp313-cp313-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/deeplatiyan/miniconda3/lib/python3.13/site-packages (from scikit-learn) (1.5.1)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.1-cp313-cp313-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.16.1-cp313-cp313-macosx_14_0_arm64.whl (20.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed scikit-learn-1.7.1 scipy-1.16.1 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d4c2395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98366eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Features:\n",
      " [[0 0 0 1 0 1]\n",
      " [1 1 0 0 0 1]\n",
      " [0 0 1 1 1 0]]\n",
      "Feature Names: ['amazing' 'is' 'learning' 'love' 'machine' 'nlp']\n",
      "\n",
      "\n",
      "TF-IDF Features:\n",
      " [[0.         0.         0.         0.70710678 0.         0.70710678]\n",
      " [0.62276601 0.62276601 0.         0.         0.         0.4736296 ]\n",
      " [0.         0.         0.62276601 0.4736296  0.62276601 0.        ]]\n",
      "Feature Names: ['amazing' 'is' 'learning' 'love' 'machine' 'nlp']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "docs = [\"I love NLP\", \"NLP is amazing\", \"I love Machine Learning\"]\n",
    "\n",
    "# 1. Bag of Words\n",
    "bow = CountVectorizer()\n",
    "X_bow = bow.fit_transform(docs)\n",
    "print(\"BoW Features:\\n\", X_bow.toarray())\n",
    "print(\"Feature Names:\", bow.get_feature_names_out())\n",
    "print()\n",
    "\n",
    "# 2. TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(docs)\n",
    "print(\"\\nTF-IDF Features:\\n\", X_tfidf.toarray())\n",
    "print(\"Feature Names:\", tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is an example of tranfer learning in DL\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained sentiment analysis model\n",
    "#classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "#print(classifier(\"I love my new phone!\"))\n",
    "# Output: [{'label': 'POSITIVE', 'score': 0.999}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2806372c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
