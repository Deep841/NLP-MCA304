{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5088,
     "status": "ok",
     "timestamp": 1754279878274,
     "user": {
      "displayName": "MANINDER KAUR",
      "userId": "13696353675143184506"
     },
     "user_tz": -330
    },
    "id": "UzsokKtl9fhR",
    "outputId": "62653ebd-eb4c-451b-8a09-7e793a913cad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /Users/deeplatiyan/miniconda3/lib/python3.13/site-packages (from nltk) (8.2.1)\n",
      "Collecting joblib (from nltk)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.7.34-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /Users/deeplatiyan/miniconda3/lib/python3.13/site-packages (from nltk) (4.67.1)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading regex-2025.7.34-cp313-cp313-macosx_11_0_arm64.whl (285 kB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Installing collected packages: regex, joblib, nltk\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [nltk][32m2/3\u001b[0m [nltk]b]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.1 nltk-3.9.1 regex-2025.7.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/deeplatiyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup: Install and Import\n",
    "!pip install nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1754279878279,
     "user": {
      "displayName": "MANINDER KAUR",
      "userId": "13696353675143184506"
     },
     "user_tz": -330
    },
    "id": "CryU-ArB-hrs"
   },
   "outputs": [],
   "source": [
    "# Sample Text\n",
    "text = \"NLTK is great for NLP! It provides easy-to-use interfaces for over 50 corpora and lexical resources.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1754279878292,
     "user": {
      "displayName": "MANINDER KAUR",
      "userId": "13696353675143184506"
     },
     "user_tz": -330
    },
    "id": "T_IH99Hn-BkI",
    "outputId": "99a57194-a375-4b44-ac89-d4f9a4740bdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokens: ['NLTK', 'is', 'great', 'for', 'NLP', '!', 'It', 'provides', 'easy-to-use', 'interfaces', 'for', 'over', '50', 'corpora', 'and', 'lexical', 'resources', '.']\n",
      "Sentence Tokens: ['NLTK is great for NLP!', 'It provides easy-to-use interfaces for over 50 corpora and lexical resources.']\n"
     ]
    }
   ],
   "source": [
    "# 1. Tokenization\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "words = word_tokenize(text)\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "print(\"Word Tokens:\", words)\n",
    "print(\"Sentence Tokens:\", sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1754279878297,
     "user": {
      "displayName": "MANINDER KAUR",
      "userId": "13696353675143184506"
     },
     "user_tz": -330
    },
    "id": "scT0kwDwMyQZ",
    "outputId": "62bbd002-897a-468f-c716-bfc4ba16600f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1754279878307,
     "user": {
      "displayName": "MANINDER KAUR",
      "userId": "13696353675143184506"
     },
     "user_tz": -330
    },
    "id": "fHC3m_XcM497",
    "outputId": "d55cb7ee-1b3a-413f-c3f6-8987ed52ef3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1754279878316,
     "user": {
      "displayName": "MANINDER KAUR",
      "userId": "13696353675143184506"
     },
     "user_tz": -330
    },
    "id": "ZNTrnbhO-Eh-",
    "outputId": "e4e9037b-d954-42c7-97b3-d193b34f8fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Text: NLTK is great for NLP It provides easytouse interfaces for over  corpora and lexical resources\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Cleaning Text\n",
    "import re\n",
    "\n",
    "# Remove punctuation and numbers\n",
    "cleaned_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "cleaned_text = re.sub(r'\\d+', '', cleaned_text)\n",
    "print(\"Cleaned Text:\", cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9G6h9RJlMvAI"
   },
   "source": [
    "| Pattern | Matches            | Effect in `re.sub()`       |\n",
    "| ------- | ------------------ | -------------------------- |\n",
    "| `\\d+`   | One or more digits | Removes full number blocks |\n",
    "| `''`    | Empty string       | Means \"delete the match\"   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1754279878324,
     "user": {
      "displayName": "MANINDER KAUR",
      "userId": "13696353675143184506"
     },
     "user_tz": -330
    },
    "id": "r0GSkwQD_BUm",
    "outputId": "93efd1b1-73a7-4ac2-86b1-114a093df714"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of cleaned_text: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Data type of cleaned_text:\", type(cleaned_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1754279878327,
     "user": {
      "displayName": "MANINDER KAUR",
      "userId": "13696353675143184506"
     },
     "user_tz": -330
    },
    "id": "GhAJUqDV-GbW",
    "outputId": "1d29b26e-20a5-42f0-9649-03e0015b7307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercased Text: nltk is great for nlp it provides easytouse interfaces for over  corpora and lexical resources\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Case Normalization\n",
    "lowercase_text = cleaned_text.lower()\n",
    "print(\"Lowercased Text:\", lowercase_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1754279878377,
     "user": {
      "displayName": "MANINDER KAUR",
      "userId": "13696353675143184506"
     },
     "user_tz": -330
    },
    "id": "0KD-mS6RNMQb",
    "outputId": "5d966c4a-9e24-4289-a0a1-3eb165843bb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lowercase_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1754279878380,
     "user": {
      "displayName": "MANINDER KAUR",
      "userId": "13696353675143184506"
     },
     "user_tz": -330
    },
    "id": "6QFzEKlR-JwF",
    "outputId": "15f6063f-3f65-4c47-ef34-754cac8498a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/deeplatiyan/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Words: ['nltk', 'great', 'nlp', 'provides', 'easytouse', 'interfaces', 'corpora', 'lexical', 'resources']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Stop Words Removal\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in word_tokenize(lowercase_text) if word not in stop_words]\n",
    "print(\"Filtered Words:\", filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "spG922fuSj9e"
   },
   "outputs": [],
   "source": [
    "# for word in word_tokenize(lowercase_text):\n",
    "#     if word not in stopwords.words('english'):\n",
    "#         filtered_words.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1754279878388,
     "user": {
      "displayName": "MANINDER KAUR",
      "userId": "13696353675143184506"
     },
     "user_tz": -330
    },
    "id": "rwFG3PfjNuOI",
    "outputId": "c7108c84-f891-47c9-da51-c42784545f74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1754279878390,
     "user": {
      "displayName": "MANINDER KAUR",
      "userId": "13696353675143184506"
     },
     "user_tz": -330
    },
    "id": "TNirwSf6-Lcq",
    "outputId": "9dcee567-54c7-44e5-c389-5fd98295838d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['nltk', 'great', 'nlp', 'provid', 'easytous', 'interfac', 'corpora', 'lexic', 'resourc']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "print(\"Stemmed Words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1754279878393,
     "user": {
      "displayName": "MANINDER KAUR",
      "userId": "13696353675143184506"
     },
     "user_tz": -330
    },
    "id": "pX9pokQp-NcS",
    "outputId": "928829f4-8c88-49f7-a421-b693f7d2484d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized Words: ['nltk', 'great', 'nlp', 'provides', 'easytouse', 'interface', 'corpus', 'lexical', 'resource']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 6. Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "print(\"Lemmatized Words:\", lemmatized_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1754279878396,
     "user": {
      "displayName": "MANINDER KAUR",
      "userId": "13696353675143184506"
     },
     "user_tz": -330
    },
    "id": "62da0nuV-PL0",
    "outputId": "477beb7a-5e50-4ef5-a6b9-00c60a2b08ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: [('NLTK', 'NNP'), ('is', 'VBZ'), ('great', 'JJ'), ('for', 'IN'), ('NLP', 'NNP'), ('!', '.'), ('It', 'PRP'), ('provides', 'VBZ'), ('easy-to-use', 'JJ'), ('interfaces', 'NNS'), ('for', 'IN'), ('over', 'IN'), ('50', 'CD'), ('corpora', 'NNS'), ('and', 'CC'), ('lexical', 'JJ'), ('resources', 'NNS'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "# 7. Part-of-Speech (POS) Tagging\n",
    "from nltk import pos_tag\n",
    "\n",
    "pos_tags = pos_tag(words)\n",
    "print(\"POS Tags:\", pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1754279878832,
     "user": {
      "displayName": "MANINDER KAUR",
      "userId": "13696353675143184506"
     },
     "user_tz": -330
    },
    "id": "PXcEpyuv9iWn",
    "outputId": "127f8145-9db0-487a-f5b6-971e2019b7ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entity Tree:\n",
      "(S\n",
      "  (ORGANIZATION NLTK/NNP)\n",
      "  is/VBZ\n",
      "  great/JJ\n",
      "  for/IN\n",
      "  (ORGANIZATION NLP/NNP)\n",
      "  !/.\n",
      "  It/PRP\n",
      "  provides/VBZ\n",
      "  easy-to-use/JJ\n",
      "  interfaces/NNS\n",
      "  for/IN\n",
      "  over/IN\n",
      "  50/CD\n",
      "  corpora/NNS\n",
      "  and/CC\n",
      "  lexical/JJ\n",
      "  resources/NNS\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# 8. Named Entity Recognition (NER)\n",
    "from nltk import ne_chunk\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "\n",
    "ner_tree = ne_chunk(pos_tags)\n",
    "print(\"Named Entity Tree:\")\n",
    "print(ner_tree)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOWz5+EnrZunNJ8qMfObXBr",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
