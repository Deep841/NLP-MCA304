{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOoh4WofYJ6Ba9sF4YB76xc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","# Download stopwords if not already done\n","nltk.download('punkt_tab')\n","nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fzPuQTjsRdPn","executionInfo":{"status":"ok","timestamp":1754280637975,"user_tz":-330,"elapsed":390,"user":{"displayName":"MANINDER KAUR","userId":"13696353675143184506"}},"outputId":"bab7c729-b2d9-4d7c-f725-08ab9bfcb546"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zqowR4lkPCTW","executionInfo":{"status":"ok","timestamp":1754280661835,"user_tz":-330,"elapsed":53,"user":{"displayName":"MANINDER KAUR","userId":"13696353675143184506"}}},"outputs":[],"source":["# Step 1: Load the default English stopwords\n","stop_words = set(stopwords.words('english'))\n","\n","# Step 2: Modify the stopword list\n","stop_words.add('nlp')                       # Add 'nlp' as a stopword\n","stop_words.update(['python', 'data'])       # Add multiple custom stopwords\n","stop_words.discard('not')                   # Keep 'not' (useful in sentiment)"]},{"cell_type":"code","source":["# Step 3: Sample text\n","text = \"Python is not bad for NLP data science tasks.\"\n","\n","# Step 4: Tokenize and filter\n","words = word_tokenize(text.lower())         # Lowercase and tokenize\n","filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n","\n","# Step 5: Print results\n","print(\"Original:\", words)\n","print(\"Filtered:\", filtered_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bvnzs15mRptX","executionInfo":{"status":"ok","timestamp":1754280667588,"user_tz":-330,"elapsed":34,"user":{"displayName":"MANINDER KAUR","userId":"13696353675143184506"}},"outputId":"19830cbf-ce09-4601-bad0-ccf8bb6d7802"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Original: ['python', 'is', 'not', 'bad', 'for', 'nlp', 'data', 'science', 'tasks', '.']\n","Filtered: ['not', 'bad', 'science', 'tasks']\n"]}]},{"cell_type":"code","source":["# filtered_words = []\n","\n","# for word in words:\n","#     if word.isalnum() and word not in stop_words:\n","#         filtered_words.append(word)\n"],"metadata":{"id":"VlNkWwhOSLP_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"48nJRXTVSA3f"}}]}